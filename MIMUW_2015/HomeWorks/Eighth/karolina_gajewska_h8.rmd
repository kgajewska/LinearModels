---
title: "Homework 8"
author: "Karolina Gajewska"
html_document:
    toc: TRUE
---
```{r, warning = FALSE, message = FALSE}
library(PBImisc)
library(lasso2)
library(glmnet)

attach(Drosophila)

```

For the Drosophila study check what will happen with coefficients if:

## a) all variables are included into a model and standard MLE estimates are calculated

```{r, warning = FALSE, message = FALSE}

mle<-list()


for ( i in 1:40){
mle[[i]] <- lm(pc1~., data=bs[,i:42])
}

plot(abs(mle[[35]]$coefficients), ylab = "Wartości_współczynników", type="l", col="yellow" )
par(new=TRUE)
plot(abs(mle[[25]]$coefficients), ylab = "Wartości_współczynników", axes = FALSE, type="l", col="orange" )
par(new=TRUE)
plot(abs(mle[[15]]$coefficients), ylab = "Wartości_współczynników", axes = FALSE, type="l", col="red" )
par(new=TRUE)
plot(abs(mle[[5]]$coefficients), ylab = "Wartości_współczynników", axes = FALSE, type="l", col="blue" )
par(new=TRUE)
plot(abs(mle[[1]]$coefficients), ylab = "Wartości_współczynników", axes = FALSE,type="l", col="black" )
```

Na podstawie wykresu możemy wnioskować, że im więcej zmiennych objaśniających zawiera model, tym mniejsze są wartości bezwzględne szacowanych współczynników modelu.


## b) ridge regression is applied


```{r, warning = FALSE, message = FALSE}
RRE <- glmnet(as.matrix(bs[, 1:41]), as.matrix(bs[, 42]), lambda = 10^((-1):2), alpha = 0)
plot(RRE, "lambda")

```

Wraz ze wzrostem lamdy, coraz większa liczba współczynników zbiega do zera.

## c) lasso regression is applied.


```{r, warning = FALSE, message = FALSE}
lasso <- glmnet(as.matrix(bs[, 1:41]), as.matrix(bs[, 42]), lambda = 3^((-15):-3), alpha = 1)
plot(lasso, "lambda")

```

Podobnie jak w poprzednim przypadku, wraz ze wzrostem lamdy, coraz większa liczba współczynników zbiega do zera, jednak tu współczynniki są bardziej zróżnicowane pod względem znaku.




